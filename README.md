## Local-AI-with-RAG

## Quick Start
### Using Google Colab 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Rsh4PNzoTi1JMrh8aIKQWECCb3JJovmy?usp=sharing)  

Click the Colab badge above to run the complete pipeline including:
1. **Input your question**
2. **Dataset download** 
3. **RAG Framework**:
   - BM25-Based Text Retrieval
   - Vector-Based Semantic Retrieval  
   - Reciprocal Rank Fusion (RRF)
4. **Locally deploy AI models by Ollama** 
5. **Answer Quality Evaluation**


### Download Models and Datasets

**Embedding Model:** `BAAI/bge-large-zh-v1.5`  
[![HuggingFace Model](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Model-blue)](https://huggingface.co/BAAI/bge-large-zh-v1.5)

**Dataset:** `Huatuo26M-Lite`  
[![HuggingFace Dataset](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-orange)](https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite)


## Description
Architecture for the Secure Deployment of Open-Source LLMs Using a Retrieval-Augmented Generation (RAG)

<img width="674" alt="image" src="https://github.com/user-attachments/assets/15f0f4a3-9908-49b7-948a-691de6c72a63" />


### Model Overview

The system consists of four main components:

**A. Inputs**
 
**B. Retrieval-Augmented Generation (RAG) Framework**

**C. Large Language Model (LLM) Core**  

**D. Answer Quality Evaluation**  



## Results
<img width="408" alt="image" src="https://github.com/user-attachments/assets/988677b7-e8e2-48ad-bc6b-c9e7d53fd179" />







