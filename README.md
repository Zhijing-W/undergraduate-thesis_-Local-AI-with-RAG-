## Local-AI-with-RAG

## Quick Start
### Using Google Colab 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/13uG_vrM-Qm189Aslaa3pH2eKWoJ8Ut47)  
Click the Colab badge above to run the complete pipeline including:
1. Dataset download from huggingface
2. Model training/inference
3. Deploy ollama

Download Embedding Model: BAAI/bge-large-zh-v1.5
[![HuggingFace Models](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Model-blue)]([https://huggingface.co/your-model](https://huggingface.co/BAAI/bge-large-zh-v1.5))

Download Datasets: Huatuo26M-Lite
[![HuggingFace Datasets](https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-orange)]([https://huggingface.co/datasets/your-dataset](https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite))



## Description
A clear one-paragraph explanation of your project.
<img width="674" alt="image" src="https://github.com/user-attachments/assets/15f0f4a3-9908-49b7-948a-691de6c72a63" />


Here is a brief description of the modelï¼Œ which has four main components.
A. Inputs
B. Retrieval-Augmented Generation (RAG) Framework
C. Large Language Model (LLM)
D. Answer Quality Evaluation

## Results
<img width="408" alt="image" src="https://github.com/user-attachments/assets/988677b7-e8e2-48ad-bc6b-c9e7d53fd179" />







